# -*- coding: utf-8 -*-
import scrapy
import urllib
from baidufanyi.items import BaidufanyiItem
from baidufanyi import settings
from scrapy_splash import SplashRequest
class FanyiSpider(scrapy.Spider):
    name = 'fanyi'
    #allowed_domains = ['sss']
    start_urls = ['https://fanyi.baidu.com/?aldtype=16047#zh/en/']
    headers = settings.HEADERS
    filepath = settings.FILEPATH

    def start_requests(self):
        # with open(self.filepath,'r') as f:
        #     kws = f.readlines()
        #     for kw in kws:
                keyword = '你好'#kw.strip()
                keywordUrl = urllib.parse.quote(keyword)
                realUrl = self.start_urls[0] + keywordUrl
                yield SplashRequest(realUrl, callback=self.parse, headers=self.headers)

    def parse(self, response):
        print(response.text)
        item = BaidufanyiItem()
        item['original'] = response.xpath('//p[contains(@class,"source-output")]/text()').extract_first()
        item['translation'] = response.xpath('//p[contains(@class,"target-output")]/text()').extract_first()
        print(item)
        yield item
